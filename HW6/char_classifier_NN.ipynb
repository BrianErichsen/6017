{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW 6: Character classification using KNN with PyTorch\n",
    "\n",
    "Author:\n",
    "</b> Brian Erichsen Fagundes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data acquision + clenup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loads data into variable\n",
    "data = pd.read_csv('ARIAL.csv')\n",
    "\n",
    "# selects which columns to keep m_label and all the r{x} c{y}\n",
    "columns_to_keep = ['m_label']\n",
    "columns_to_keep += [f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# funtion that transforms dataframe returns 2 numpy arrays\n",
    "# x sample x 20 x 20 has pixel val, y #samples x 1 array has ascii for each char\n",
    "def transform_data(data_frame):\n",
    "    # extract the pixel val and normalize data\n",
    "    # . values converts from pandas to numpy array\n",
    "    Xs = data_frame[[f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]].values\n",
    "    # makes it samples x 20 x 20 D / 256.0\n",
    "    Xs = Xs.reshape(-1, 20, 20) / 256.0\n",
    "\n",
    "    # extrac the ascii value for each char\n",
    "    Ys = data_frame['m_label'].values\n",
    "    # makes samples# x 1 Dim\n",
    "    Ys = Ys.reshape(-1, 1)\n",
    "\n",
    "    return Xs, Ys\n",
    "\n",
    "Xs, Ys = transform_data(filtered_data)\n",
    "\n",
    "# dictionary for label conversion - using set (collection of unique elements)\n",
    "unique_chars = sorted(set(filtered_data['m_label']))\n",
    "# maps each char to unique index\n",
    "char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "# maps each index back to char\n",
    "index_to_char = {idx: char for char, idx in char_to_index.items()}\n",
    "\n",
    "# convert labels to indices\n",
    "Ys = np.array([char_to_index[char] for char in Ys.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 7.0393\n",
      "Epoch [1], Step [400], Loss: 6.1913\n",
      "Epoch [1], Step [600], Loss: 5.6102\n",
      "Epoch [1], Step [800], Loss: 5.2848\n",
      "Epoch [2], Step [200], Loss: 4.6941\n",
      "Epoch [2], Step [400], Loss: 4.3531\n",
      "Epoch [2], Step [600], Loss: 3.9506\n",
      "Epoch [2], Step [800], Loss: 3.6667\n",
      "Epoch [3], Step [200], Loss: 3.0192\n",
      "Epoch [3], Step [400], Loss: 2.7712\n",
      "Epoch [3], Step [600], Loss: 2.6210\n",
      "Epoch [3], Step [800], Loss: 2.4629\n",
      "Epoch [4], Step [200], Loss: 2.0221\n",
      "Epoch [4], Step [400], Loss: 1.9825\n",
      "Epoch [4], Step [600], Loss: 1.9873\n",
      "Epoch [4], Step [800], Loss: 1.8426\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a Pytorch network where its archecture is\n",
    "    # Convolution 2D layer (relu)\n",
    "    # Max pooling layer\n",
    "    # Convolution, another Max pooling\n",
    "    # Dense layer (relu), dense layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Tensor is numpy multi dim array\n",
    "# Convert data to PyTorch tensors\n",
    "Xs = torch.tensor(Xs, dtype=torch.float32).reshape(-1, 1, 20, 20) # between 0 and 1\n",
    "Ys = torch.tensor(Ys, dtype=torch.long) # can be long int\n",
    "\n",
    "# So we can iterate over batches\n",
    "dataset = TensorDataset(Xs, Ys)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Network as a class with a constructor and forward method\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1d input, 6 outputs and 3 x 3 pixels kernel filter\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        # kernel size of 2, reduces spatial dim by half, with stride of 2 for 2x2 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 6 from the 6 output layer in the 1st convolution layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # first dense layer has 16 * 3 * 3 input features and 120 neurons (output features)\n",
    "        # after second pooling layer, we have 16 channels 3 x 3\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, len(unique_chars))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))# conv1 -> relu -> max pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))# conv2 -> relu -> max pool\n",
    "        x = x.view(-1, 16 * 3 * 3)# flattens the tensor back to 1 D\n",
    "        x = F.relu(self.fc1(x)) # FC1 -> relu\n",
    "        #x = F.relu(self.fc2(x)) # FC2 -> relu\n",
    "        x = self.fc3(x) # last dense layer\n",
    "        return x\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "# remember that cuda is using GPU with parallelism\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "net = Net().to(device)\n",
    "# measures error for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# uses ADAM optimizer to find the best weights\n",
    "optmizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# training function\n",
    "def train(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            #inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the param gradients\n",
    "            optmizer.zero_grad()\n",
    "            outputs = model(inputs) # predict the output with training data\n",
    "            loss = criterion(outputs, labels) # see how well we did\n",
    "            loss.backward() # see how to change weight to do better\n",
    "            optmizer.step() # actually changes the weights\n",
    "            running_loss += loss.item()\n",
    "            # prints every 200 batch statistics\n",
    "            if i % 200 == 199:\n",
    "                print(f'Epoch [{epoch + 1}], Step [{i + 1}], Loss: {running_loss / 200:.4f}')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "train(net, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 57.38%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate function\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            #images, labels = images.to(device), labels.to(device).view(-1)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network: { 100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
