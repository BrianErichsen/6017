{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HW 6: Character classification using KNN with PyTorch\n",
    "\n",
    "Author:\n",
    "</b> Brian Erichsen Fagundes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data acquision + clenup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loads data into variable\n",
    "data = pd.read_csv('ARIAL.csv')\n",
    "\n",
    "# selects which columns to keep m_label and all the r{x} c{y}\n",
    "columns_to_keep = ['m_label']\n",
    "columns_to_keep += [f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# funtion that transforms dataframe returns 2 numpy arrays\n",
    "# x sample x 20 x 20 has pixel val, y #samples x 1 array has ascii for each char\n",
    "def transform_data(data_frame):\n",
    "    # extract the pixel val and normalize data\n",
    "    # . values converts from pandas to numpy array\n",
    "    Xs = data_frame[[f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]].values\n",
    "    # makes it samples x 20 x 20 D / 256.0\n",
    "    Xs = Xs.reshape(-1, 20, 20) / 256.0\n",
    "\n",
    "    # extrac the ascii value for each char\n",
    "    Ys = data_frame['m_label'].values\n",
    "    # makes samples# x 1 Dim\n",
    "    Ys = Ys.reshape(-1, 1)\n",
    "\n",
    "    return Xs, Ys\n",
    "\n",
    "Xs, Ys = transform_data(filtered_data)\n",
    "\n",
    "# dictionary for label conversion - using set (collection of unique elements)\n",
    "unique_chars = sorted(set(filtered_data['m_label']))\n",
    "# maps each char to unique index\n",
    "char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "# maps each index back to char\n",
    "index_to_char = {idx: char for char, idx in char_to_index.items()}\n",
    "\n",
    "# convert labels to indices\n",
    "Ys = np.array([char_to_index[char] for char in Ys.flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2: Build a Pytorch network</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 6.9383\n",
      "Epoch [1], Step [400], Loss: 5.7744\n",
      "Epoch [1], Step [600], Loss: 5.3444\n",
      "Epoch [1], Step [800], Loss: 4.9814\n",
      "Epoch [2], Step [200], Loss: 4.1703\n",
      "Epoch [2], Step [400], Loss: 3.6756\n",
      "Epoch [2], Step [600], Loss: 3.3063\n",
      "Epoch [2], Step [800], Loss: 2.9941\n",
      "Epoch [3], Step [200], Loss: 2.3600\n",
      "Epoch [3], Step [400], Loss: 2.2110\n",
      "Epoch [3], Step [600], Loss: 2.0563\n",
      "Epoch [3], Step [800], Loss: 1.9921\n",
      "Epoch [4], Step [200], Loss: 1.6616\n",
      "Epoch [4], Step [400], Loss: 1.6788\n",
      "Epoch [4], Step [600], Loss: 1.6410\n",
      "Epoch [4], Step [800], Loss: 1.6299\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a Pytorch network where its archecture is\n",
    "    # Convolution 2D layer (relu)\n",
    "    # Max pooling layer\n",
    "    # Convolution, another Max pooling\n",
    "    # Dense layer (relu), dense layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Tensor is numpy multi dim array\n",
    "# Convert data to PyTorch tensors\n",
    "Xs = torch.tensor(Xs, dtype=torch.float32).reshape(-1, 1, 20, 20) # between 0 and 1\n",
    "Ys = torch.tensor(Ys, dtype=torch.long) # can be long int\n",
    "\n",
    "# So we can iterate over batches\n",
    "dataset = TensorDataset(Xs, Ys)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Network as a class with a constructor and forward method\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # parent class\n",
    "        super(Net, self).__init__()\n",
    "        # 1d input, 6 outputs and 3 x 3 pixels kernel filter\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        # kernel size of 2, reduces spatial dim by half, with stride of 2 for 2x2 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #conv1 output - ((input size - kernel size + 2 x Padding) / Stride)+1\n",
    "        # 20 - 3 / 1 + 1 -- 18 x 18\n",
    "        # after first pooling -- 9 x 9 size instead of 18 x 18\n",
    "        # 6 from the 6 output layer in the 1st convolution layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # 9 - 3 / 1 + 1 -- 7 x 7\n",
    "        # after second layer of pooling - 3 x 3\n",
    "        # first dense layer has 16 * 3 * 3 input features and 120 neurons (output features)\n",
    "        # after second pooling layer, we have 16 channels 3 x 3\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "                            # (84, num of classes)\n",
    "        self.fc3 = nn.Linear(120, len(unique_chars))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))# conv1 -> relu -> max pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))# conv2 -> relu -> max pool\n",
    "        x = x.view(-1, 16 * 3 * 3)# flattens the tensor back to 1 D\n",
    "        x = F.relu(self.fc1(x)) # FC1 -> relu\n",
    "        #x = F.relu(self.fc2(x)) # FC2 -> relu\n",
    "        x = self.fc3(x) # last dense layer\n",
    "        return x\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "# remember that cuda is using GPU with parallelism\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "net = Net().to(device)\n",
    "# measures error for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# uses ADAM optimizer to find the best weights\n",
    "optmizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# training function\n",
    "def train(model,train_loader, optmizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            #inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the param gradients\n",
    "            optmizer.zero_grad()\n",
    "            outputs = model(inputs) # predict the output with training data\n",
    "            loss = criterion(outputs, labels) # see how well we did\n",
    "            loss.backward() # see how to change weight to do better\n",
    "            optmizer.step() # actually changes the weights\n",
    "            running_loss += loss.item()\n",
    "            # prints every 200 batch statistics\n",
    "            if i % 200 == 199:\n",
    "                print(f'Epoch [{epoch + 1}], Step [{i + 1}], Loss: {running_loss / 200:.4f}')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "train(net,train_loader, optmizer, criterion, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 60.80%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            #images, labels = images.to(device), labels.to(device).view(-1)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network: { 100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3: Exploration and Evaluation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network using cross validation\n",
    "# (splitting data into training/testing). What is its accuracy?\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# random number is arbitrary\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xs, Ys, test_size=0.2, random_state=42)\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# function to properly train NN and do a Evaluation with Cross-Validation\n",
    "def validade_CV(model, test_dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            #images, labels = images.to(device), labels.to(device).view(-1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_loss /= len(test_dataset)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 1.4098\n",
      "Epoch [1], Step [400], Loss: 1.4298\n",
      "Epoch [1], Step [600], Loss: 1.4352\n",
      "Epoch [2], Step [200], Loss: 1.2303\n",
      "Epoch [2], Step [400], Loss: 1.2976\n",
      "Epoch [2], Step [600], Loss: 1.2794\n",
      "Epoch [3], Step [200], Loss: 1.1240\n",
      "Epoch [3], Step [400], Loss: 1.1802\n",
      "Epoch [3], Step [600], Loss: 1.2106\n",
      "Epoch [4], Step [200], Loss: 1.0479\n",
      "Epoch [4], Step [400], Loss: 1.1104\n",
      "Epoch [4], Step [600], Loss: 1.1287\n",
      "Finished Training\n",
      "Validation Loss: 59.17%\n"
     ]
    }
   ],
   "source": [
    "train(net,train_loader, optmizer, criterion , 4)\n",
    "validade_CV(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create and train a different topology, adding more convolutiuon layers\n",
    "class NetImproved(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetImproved, self).__init__()\n",
    "        a = 1 # solve for a ...\n",
    "        # 1d input, 6 outputs and 3 x 3 pixels kernel filter\n",
    "        c1Out = 6\n",
    "        c2Out = 16\n",
    "        c3Out = 32\n",
    "        self.conv1 = nn.Conv2d(1, c1Out, 3)\n",
    "        # convoluted layer 1 output -> 20 - 3 + 1 --18 x 18\n",
    "        # first pooling layer -- 9 x 9\n",
    "        self.conv2 = nn.Conv2d(c1Out, c2Out, 3)\n",
    "        # convoluted layer 2 output -> 9 - 3 + 1 -- 7 x 7\n",
    "        # second pooling layer -- 3 x 3\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(c2Out, c3Out, 3)\n",
    "        # convoluted layer 3 output -> 3 - 3 + 1 -- 1\n",
    "        self.pooledOutputSize = c3Out * a * a\n",
    "        #self.fc1 = nn.Linear(self.pooledOutputSize, 120)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.pooledOutputSize, 120),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, len(unique_chars)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.pooledOutputSize)\n",
    "        x = F.relu(self. fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net_improved = NetImproved().to(device)\n",
    "optimizer_improved = optim.Adam(net_improved.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 7.8146\n",
      "Epoch [1], Step [400], Loss: 7.4588\n",
      "Epoch [1], Step [600], Loss: 7.2730\n",
      "Epoch [2], Step [200], Loss: 7.1072\n",
      "Epoch [2], Step [400], Loss: 7.0128\n",
      "Epoch [2], Step [600], Loss: 6.9022\n",
      "Epoch [3], Step [200], Loss: 6.8987\n",
      "Epoch [3], Step [400], Loss: 6.8536\n",
      "Epoch [3], Step [600], Loss: 6.9197\n",
      "Epoch [4], Step [200], Loss: 6.7854\n",
      "Epoch [4], Step [400], Loss: 6.8172\n",
      "Epoch [4], Step [600], Loss: 6.7597\n",
      "Epoch [5], Step [200], Loss: 6.7439\n",
      "Epoch [5], Step [400], Loss: 6.6930\n",
      "Epoch [5], Step [600], Loss: 6.7581\n",
      "Epoch [6], Step [200], Loss: 6.7291\n",
      "Epoch [6], Step [400], Loss: 6.6647\n",
      "Epoch [6], Step [600], Loss: 6.6543\n",
      "Epoch [7], Step [200], Loss: 6.6839\n",
      "Epoch [7], Step [400], Loss: 6.7037\n",
      "Epoch [7], Step [600], Loss: 6.6192\n",
      "Epoch [8], Step [200], Loss: 6.5805\n",
      "Epoch [8], Step [400], Loss: 6.6784\n",
      "Epoch [8], Step [600], Loss: 6.5894\n",
      "Epoch [9], Step [200], Loss: 6.5938\n",
      "Epoch [9], Step [400], Loss: 6.6070\n",
      "Epoch [9], Step [600], Loss: 6.5617\n",
      "Epoch [10], Step [200], Loss: 6.5970\n",
      "Epoch [10], Step [400], Loss: 6.4685\n",
      "Epoch [10], Step [600], Loss: 6.5252\n",
      "Finished Training\n",
      "Validation Loss: 31.00%\n",
      "Accuracy of the network: 31.00%\n"
     ]
    }
   ],
   "source": [
    "train(net_improved,train_loader, optimizer_improved, criterion, 10)\n",
    "validade_CV(net_improved, test_loader)\n",
    "evaluate(net_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that sometimes adding more layers can decrease the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try a different topology since the previous attempt yielded a low\n",
    "# Here I used same number of convoluted layers and fully connected layers as well\n",
    "# but added batch normalization for stabalize and accelerate training\n",
    "# and dropout as well after each FC layer to prevent overfitting\n",
    "\n",
    "# Network as a class with a constructor and forward method\n",
    "class NetImproved2(nn.Module):\n",
    "    def __init__(self):\n",
    "        # parent class\n",
    "        super(NetImproved2, self).__init__()\n",
    "        # 1d input, 6 outputs and 3 x 3 pixels kernel filter\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(6)\n",
    "        # kernel size of 2, reduces spatial dim by half, with stride of 2 for 2x2 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #conv1 output - ((input size - kernel size + 2 x Padding) / Stride)+1\n",
    "        # 20 - 3 / 1 + 1 -- 18 x 18\n",
    "        # after first pooling -- 9 x 9 size instead of 18 x 18\n",
    "        # 6 from the 6 output layer in the 1st convolution layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(16)\n",
    "        # 9 - 3 / 1 + 1 -- 7 x 7\n",
    "        # after second layer of pooling - 3 x 3\n",
    "        # first dense layer has 16 * 3 * 3 input features and 120 neurons (output features)\n",
    "        # after second pooling layer, we have 16 channels 3 x 3\n",
    "        self.fc1 = nn.Linear(16 * 3 * 3, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, len(unique_chars))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))# conv1 -> relu -> max pool\n",
    "        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))# conv2 -> relu -> max pool\n",
    "        x = x.view(-1, 16 * 3 * 3)# flattens the tensor back to 1 D\n",
    "        x = self.dropout(F.relu(self.fc1(x))) # FC1 -> relu\n",
    "        #x = F.relu(self.fc2(x)) # FC2 -> relu\n",
    "        x = self.fc3(x) # last dense layer\n",
    "        return x\n",
    "\n",
    "net_improved = NetImproved2().to(device)\n",
    "optimizer_improved = optim.Adam(net_improved.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 6.5024\n",
      "Epoch [1], Step [400], Loss: 5.5669\n",
      "Epoch [1], Step [600], Loss: 5.3243\n",
      "Epoch [2], Step [200], Loss: 4.7789\n",
      "Epoch [2], Step [400], Loss: 4.6169\n",
      "Epoch [2], Step [600], Loss: 4.3285\n",
      "Epoch [3], Step [200], Loss: 3.9455\n",
      "Epoch [3], Step [400], Loss: 3.8206\n",
      "Epoch [3], Step [600], Loss: 3.6748\n",
      "Epoch [4], Step [200], Loss: 3.3406\n",
      "Epoch [4], Step [400], Loss: 3.1526\n",
      "Epoch [4], Step [600], Loss: 3.0366\n",
      "Epoch [5], Step [200], Loss: 2.7670\n",
      "Epoch [5], Step [400], Loss: 2.7337\n",
      "Epoch [5], Step [600], Loss: 2.7113\n",
      "Epoch [6], Step [200], Loss: 2.3823\n",
      "Epoch [6], Step [400], Loss: 2.3738\n",
      "Epoch [6], Step [600], Loss: 2.3875\n",
      "Epoch [7], Step [200], Loss: 2.1171\n",
      "Epoch [7], Step [400], Loss: 2.1198\n",
      "Epoch [7], Step [600], Loss: 2.1720\n",
      "Epoch [8], Step [200], Loss: 1.9933\n",
      "Epoch [8], Step [400], Loss: 1.9430\n",
      "Epoch [8], Step [600], Loss: 1.9560\n",
      "Epoch [9], Step [200], Loss: 1.8002\n",
      "Epoch [9], Step [400], Loss: 1.7667\n",
      "Epoch [9], Step [600], Loss: 1.8112\n",
      "Epoch [10], Step [200], Loss: 1.6599\n",
      "Epoch [10], Step [400], Loss: 1.6969\n",
      "Epoch [10], Step [600], Loss: 1.6926\n",
      "Finished Training\n",
      "Validation Loss: 55.14%\n",
      "Accuracy of the network: 55.14%\n"
     ]
    }
   ],
   "source": [
    "train(net_improved,train_loader, optimizer_improved, criterion, 10)\n",
    "validade_CV(net_improved, test_loader)\n",
    "evaluate(net_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding batch normalization for stabalize and accelerate training\n",
    "\n",
    "and dropout as well after each fully connected layer to prevent overfitting we were\n",
    "\n",
    "able to increase accuracy of the network to 81.03%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try a slightly different topology using bigger kernel size for\n",
    "# the convolution layers\n",
    "\n",
    "\n",
    "# Network as a class with a constructor and forward method\n",
    "class NetImproved3(nn.Module):\n",
    "    def __init__(self):\n",
    "        # parent class\n",
    "        super(NetImproved3, self).__init__()\n",
    "        # 1d input, 6 outputs and 5 x 5 pixels kernel filter\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(6)\n",
    "        # kernel size of 2, reduces spatial dim by half, with stride of 2 for 2x2 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #conv1 output - ((input size - kernel size + 2 x Padding) / Stride)+1\n",
    "        # 20 - 5 / 1 + 1 -- 16 x 16\n",
    "        # after first pooling -- 8 x 8 size instead of 16 x 16\n",
    "        # 6 from the 6 output layer in the 1st convolution layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(16)\n",
    "        # 8 - 5 / 1 + 1 -- 4 x 4\n",
    "        # after second layer of pooling - 2 x 2\n",
    "        # first dense layer has 16 * 3 * 3 input features and 120 neurons (output features)\n",
    "        # after second pooling layer, we have 16 channels 3 x 3\n",
    "        self.fc1 = nn.Linear(16 * 2 * 2, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(120, len(unique_chars))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))# conv1 -> relu -> max pool\n",
    "        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))# conv2 -> relu -> max pool\n",
    "        x = x.view(-1, 16 * 2 * 2)# flattens the tensor back to 1 D\n",
    "        x = self.dropout(F.relu(self.fc1(x))) # FC1 -> relu\n",
    "        #x = F.relu(self.fc2(x)) # FC2 -> relu\n",
    "        x = self.fc3(x) # last dense layer\n",
    "        return x\n",
    "\n",
    "net_improved = NetImproved3().to(device)\n",
    "optimizer_improved = optim.Adam(net_improved.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 6.4814\n",
      "Epoch [1], Step [400], Loss: 5.5625\n",
      "Epoch [1], Step [600], Loss: 5.2458\n",
      "Epoch [2], Step [200], Loss: 4.6857\n",
      "Epoch [2], Step [400], Loss: 4.4841\n",
      "Epoch [2], Step [600], Loss: 4.2978\n",
      "Epoch [3], Step [200], Loss: 3.8488\n",
      "Epoch [3], Step [400], Loss: 3.7360\n",
      "Epoch [3], Step [600], Loss: 3.5587\n",
      "Epoch [4], Step [200], Loss: 3.2072\n",
      "Epoch [4], Step [400], Loss: 3.1462\n",
      "Epoch [4], Step [600], Loss: 3.0437\n",
      "Epoch [5], Step [200], Loss: 2.7302\n",
      "Epoch [5], Step [400], Loss: 2.7330\n",
      "Epoch [5], Step [600], Loss: 2.6570\n",
      "Epoch [6], Step [200], Loss: 2.4078\n",
      "Epoch [6], Step [400], Loss: 2.4030\n",
      "Epoch [6], Step [600], Loss: 2.3576\n",
      "Epoch [7], Step [200], Loss: 2.2048\n",
      "Epoch [7], Step [400], Loss: 2.1345\n",
      "Epoch [7], Step [600], Loss: 2.1486\n",
      "Epoch [8], Step [200], Loss: 1.9463\n",
      "Epoch [8], Step [400], Loss: 2.0055\n",
      "Epoch [8], Step [600], Loss: 2.0360\n",
      "Epoch [9], Step [200], Loss: 1.8452\n",
      "Epoch [9], Step [400], Loss: 1.8752\n",
      "Epoch [9], Step [600], Loss: 1.8392\n",
      "Epoch [10], Step [200], Loss: 1.7099\n",
      "Epoch [10], Step [400], Loss: 1.7475\n",
      "Epoch [10], Step [600], Loss: 1.7616\n",
      "Finished Training\n",
      "Validation Loss: 54.33%\n",
      "Accuracy of the network: 54.33%\n"
     ]
    }
   ],
   "source": [
    "train(net_improved,train_loader, optimizer_improved, criterion, 10)\n",
    "validade_CV(net_improved, test_loader)\n",
    "evaluate(net_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the accuracy with char inputs from different front set and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 6.9750\n",
      "Epoch [1], Step [400], Loss: 5.9262\n",
      "Epoch [1], Step [600], Loss: 5.3206\n",
      "Epoch [2], Step [200], Loss: 4.6045\n",
      "Epoch [2], Step [400], Loss: 4.1982\n",
      "Epoch [2], Step [600], Loss: 3.7747\n",
      "Epoch [3], Step [200], Loss: 2.9396\n",
      "Epoch [3], Step [400], Loss: 2.7455\n",
      "Epoch [3], Step [600], Loss: 2.5312\n",
      "Epoch [4], Step [200], Loss: 2.0059\n",
      "Epoch [4], Step [400], Loss: 1.9819\n",
      "Epoch [4], Step [600], Loss: 1.9337\n",
      "Epoch [5], Step [200], Loss: 1.5943\n",
      "Epoch [5], Step [400], Loss: 1.6361\n",
      "Epoch [5], Step [600], Loss: 1.6479\n",
      "Epoch [6], Step [200], Loss: 1.3833\n",
      "Epoch [6], Step [400], Loss: 1.4287\n",
      "Epoch [6], Step [600], Loss: 1.4282\n",
      "Epoch [7], Step [200], Loss: 1.2718\n",
      "Epoch [7], Step [400], Loss: 1.2640\n",
      "Epoch [7], Step [600], Loss: 1.3043\n",
      "Epoch [8], Step [200], Loss: 1.1324\n",
      "Epoch [8], Step [400], Loss: 1.1955\n",
      "Epoch [8], Step [600], Loss: 1.1993\n",
      "Epoch [9], Step [200], Loss: 1.0510\n",
      "Epoch [9], Step [400], Loss: 1.1292\n",
      "Epoch [9], Step [600], Loss: 1.1314\n",
      "Epoch [10], Step [200], Loss: 0.9935\n",
      "Epoch [10], Step [400], Loss: 1.0497\n",
      "Epoch [10], Step [600], Loss: 1.0783\n",
      "Finished Training\n",
      "Validation Loss: 55.24%\n",
      "Accuracy of the network: 55.24%\n"
     ]
    }
   ],
   "source": [
    "# Here we load ARIAL data into model and check accuracy for comparison\n",
    "\n",
    "# loads data into variable\n",
    "data = pd.read_csv('ARIAL.csv')\n",
    "\n",
    "# selects which columns to keep m_label and all the r{x} c{y}\n",
    "columns_to_keep = ['m_label']\n",
    "columns_to_keep += [f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "Xs, Ys = transform_data(filtered_data)\n",
    "\n",
    "# convert labels to indices\n",
    "Ys = np.array([char_to_index[char] for char in Ys.flatten()])\n",
    "\n",
    "# Tensor is numpy multi dim array\n",
    "# Convert data to PyTorch tensors\n",
    "Xs = torch.tensor(Xs, dtype=torch.float32).reshape(-1, 1, 20, 20) # between 0 and 1\n",
    "Ys = torch.tensor(Ys, dtype=torch.long) # can be long int\n",
    "\n",
    "# random number is arbitrary\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xs, Ys, test_size=0.2, random_state=42)\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "# remember that cuda is using GPU with parallelism\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "net = Net().to(device)\n",
    "# measures error for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# uses ADAM optimizer to find the best weights\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train(net, train_loader, optimizer, criterion, 10)\n",
    "validade_CV(net, test_loader)\n",
    "evaluate(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the different font set TIMES instead of ARIAL, using the 1st topology of NN the accuracy of the model seemed to decrease accuracy slightly to when training with arial instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 6.5198\n",
      "Epoch [1], Step [400], Loss: 5.6791\n",
      "Epoch [1], Step [600], Loss: 5.3626\n",
      "Epoch [2], Step [200], Loss: 4.8440\n",
      "Epoch [2], Step [400], Loss: 4.6748\n",
      "Epoch [2], Step [600], Loss: 4.3630\n",
      "Epoch [3], Step [200], Loss: 4.0299\n",
      "Epoch [3], Step [400], Loss: 3.9295\n",
      "Epoch [3], Step [600], Loss: 3.7600\n",
      "Epoch [4], Step [200], Loss: 3.4349\n",
      "Epoch [4], Step [400], Loss: 3.3536\n",
      "Epoch [4], Step [600], Loss: 3.2090\n",
      "Epoch [5], Step [200], Loss: 3.0044\n",
      "Epoch [5], Step [400], Loss: 2.8628\n",
      "Epoch [5], Step [600], Loss: 2.8007\n",
      "Epoch [6], Step [200], Loss: 2.6093\n",
      "Epoch [6], Step [400], Loss: 2.5349\n",
      "Epoch [6], Step [600], Loss: 2.5076\n",
      "Epoch [7], Step [200], Loss: 2.3189\n",
      "Epoch [7], Step [400], Loss: 2.3326\n",
      "Epoch [7], Step [600], Loss: 2.2736\n",
      "Epoch [8], Step [200], Loss: 2.0962\n",
      "Epoch [8], Step [400], Loss: 2.0970\n",
      "Epoch [8], Step [600], Loss: 2.0992\n",
      "Epoch [9], Step [200], Loss: 1.9371\n",
      "Epoch [9], Step [400], Loss: 1.9337\n",
      "Epoch [9], Step [600], Loss: 1.9322\n",
      "Epoch [10], Step [200], Loss: 1.8022\n",
      "Epoch [10], Step [400], Loss: 1.8550\n",
      "Epoch [10], Step [600], Loss: 1.8077\n",
      "Finished Training\n",
      "Validation Loss: 54.59%\n",
      "Accuracy of the network: 54.59%\n",
      "Epoch [1], Step [200], Loss: 6.4073\n",
      "Epoch [1], Step [400], Loss: 5.5743\n",
      "Epoch [1], Step [600], Loss: 5.2047\n",
      "Epoch [2], Step [200], Loss: 4.6925\n",
      "Epoch [2], Step [400], Loss: 4.4101\n",
      "Epoch [2], Step [600], Loss: 4.2656\n",
      "Epoch [3], Step [200], Loss: 3.8636\n",
      "Epoch [3], Step [400], Loss: 3.6948\n",
      "Epoch [3], Step [600], Loss: 3.4679\n",
      "Epoch [4], Step [200], Loss: 3.2051\n",
      "Epoch [4], Step [400], Loss: 3.0897\n",
      "Epoch [4], Step [600], Loss: 3.0413\n",
      "Epoch [5], Step [200], Loss: 2.7683\n",
      "Epoch [5], Step [400], Loss: 2.6826\n",
      "Epoch [5], Step [600], Loss: 2.6149\n",
      "Epoch [6], Step [200], Loss: 2.3605\n",
      "Epoch [6], Step [400], Loss: 2.4043\n",
      "Epoch [6], Step [600], Loss: 2.3647\n",
      "Epoch [7], Step [200], Loss: 2.1799\n",
      "Epoch [7], Step [400], Loss: 2.1443\n",
      "Epoch [7], Step [600], Loss: 2.0895\n",
      "Epoch [8], Step [200], Loss: 2.0057\n",
      "Epoch [8], Step [400], Loss: 1.9848\n",
      "Epoch [8], Step [600], Loss: 1.9750\n",
      "Epoch [9], Step [200], Loss: 1.8230\n",
      "Epoch [9], Step [400], Loss: 1.8826\n",
      "Epoch [9], Step [600], Loss: 1.8595\n",
      "Epoch [10], Step [200], Loss: 1.7381\n",
      "Epoch [10], Step [400], Loss: 1.7382\n",
      "Epoch [10], Step [600], Loss: 1.7692\n",
      "Finished Training\n",
      "Validation Loss: 54.31%\n",
      "Accuracy of the network: 54.31%\n"
     ]
    }
   ],
   "source": [
    "net_improved = NetImproved2().to(device)\n",
    "optimizer_improved = optim.Adam(net_improved.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net_improved,train_loader, optimizer_improved, criterion, 10)\n",
    "validade_CV(net_improved, test_loader)\n",
    "evaluate(net_improved)\n",
    "\n",
    "net_improved = NetImproved3().to(device)\n",
    "optimizer_improved = optim.Adam(net_improved.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net_improved,train_loader, optimizer_improved, criterion, 10)\n",
    "validade_CV(net_improved, test_loader)\n",
    "evaluate(net_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to see some results with training the NN with 2 different fonts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [200], Loss: 7.2909\n",
      "Epoch [1], Step [400], Loss: 6.6004\n",
      "Epoch [1], Step [600], Loss: 6.0636\n",
      "Epoch [1], Step [800], Loss: 5.6946\n",
      "Epoch [2], Step [200], Loss: 4.7245\n",
      "Epoch [2], Step [400], Loss: 4.2984\n",
      "Epoch [2], Step [600], Loss: 3.8616\n",
      "Epoch [2], Step [800], Loss: 3.5163\n",
      "Epoch [3], Step [200], Loss: 2.7176\n",
      "Epoch [3], Step [400], Loss: 2.5537\n",
      "Epoch [3], Step [600], Loss: 2.4847\n",
      "Epoch [3], Step [800], Loss: 2.3618\n",
      "Epoch [4], Step [200], Loss: 1.9630\n",
      "Epoch [4], Step [400], Loss: 1.9675\n",
      "Epoch [4], Step [600], Loss: 1.9750\n",
      "Epoch [4], Step [800], Loss: 1.8956\n",
      "Epoch [5], Step [200], Loss: 1.6597\n",
      "Epoch [5], Step [400], Loss: 1.6433\n",
      "Epoch [5], Step [600], Loss: 1.7062\n",
      "Epoch [5], Step [800], Loss: 1.6699\n",
      "Epoch [6], Step [200], Loss: 1.4613\n",
      "Epoch [6], Step [400], Loss: 1.4835\n",
      "Epoch [6], Step [600], Loss: 1.5076\n",
      "Epoch [6], Step [800], Loss: 1.4733\n",
      "Epoch [7], Step [200], Loss: 1.2882\n",
      "Epoch [7], Step [400], Loss: 1.3369\n",
      "Epoch [7], Step [600], Loss: 1.3553\n",
      "Epoch [7], Step [800], Loss: 1.3796\n",
      "Epoch [8], Step [200], Loss: 1.2137\n",
      "Epoch [8], Step [400], Loss: 1.2206\n",
      "Epoch [8], Step [600], Loss: 1.2700\n",
      "Epoch [8], Step [800], Loss: 1.2834\n",
      "Epoch [9], Step [200], Loss: 1.0741\n",
      "Epoch [9], Step [400], Loss: 1.1856\n",
      "Epoch [9], Step [600], Loss: 1.1728\n",
      "Epoch [9], Step [800], Loss: 1.2132\n",
      "Epoch [10], Step [200], Loss: 1.0257\n",
      "Epoch [10], Step [400], Loss: 1.0863\n",
      "Epoch [10], Step [600], Loss: 1.1115\n",
      "Epoch [10], Step [800], Loss: 1.1118\n",
      "Finished Training\n",
      "Validation Loss: 51.72%\n",
      "Accuracy of the network: 51.72%\n"
     ]
    }
   ],
   "source": [
    "# concatenate both files data\n",
    "arial_data = pd.read_csv('ARIAL.csv')\n",
    "times_data = pd.read_csv('TIMES.csv')\n",
    "\n",
    "data = pd.concat([arial_data, times_data])\n",
    "\n",
    "# selects which columns to keep m_label and all the r{x} c{y}\n",
    "columns_to_keep = ['m_label']\n",
    "columns_to_keep += [f'r{r}c{c}' for r in range(0, 20) for c in range(0, 20)]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "Xs, Ys = transform_data(filtered_data)\n",
    "# convert labels to indices\n",
    "Ys = np.array([char_to_index[char] for char in Ys.flatten()])\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "Xs = torch.tensor(Xs, dtype=torch.float32).reshape(-1, 1, 20, 20) # between 0 and 1\n",
    "Ys = torch.tensor(Ys, dtype=torch.long) # can be long int\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xs, Ys, test_size=0.2, random_state=42)\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "net = Net().to(device)\n",
    "# measures error for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# uses ADAM optimizer to find the best weights\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train(net, train_loader, optimizer, criterion, 10)\n",
    "validade_CV(net, test_loader)\n",
    "evaluate(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
